{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf77b4cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Wrote summary with shape (7, 8) to: metrics_summary.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OpenMathInstruct-2__avg_abs_diff</th>\n",
       "      <th>OpenMathInstruct-2__latency_mean_s</th>\n",
       "      <th>ai2_arc__latency_mean_s</th>\n",
       "      <th>ai2_arc__macro_f1</th>\n",
       "      <th>boolq__latency_mean_s</th>\n",
       "      <th>boolq__macro_f1</th>\n",
       "      <th>squad_v2__F1</th>\n",
       "      <th>squad_v2__latency_mean_s</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Qwen3-0.6B-arc_SFT_None_Lora32</th>\n",
       "      <td>22870.653666</td>\n",
       "      <td>0.4439</td>\n",
       "      <td>0.1595</td>\n",
       "      <td>0.4880</td>\n",
       "      <td>0.1599</td>\n",
       "      <td>0.3367</td>\n",
       "      <td>8.59</td>\n",
       "      <td>0.1958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen3-0.6B-arc_SFT_None_Lora64</th>\n",
       "      <td>22870.688842</td>\n",
       "      <td>0.1811</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.4937</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.3241</td>\n",
       "      <td>8.09</td>\n",
       "      <td>0.1952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen3-0.6B-boolq_SFT_None_Lora32</th>\n",
       "      <td>25172.044530</td>\n",
       "      <td>4.7384</td>\n",
       "      <td>0.9745</td>\n",
       "      <td>0.5021</td>\n",
       "      <td>0.1530</td>\n",
       "      <td>0.3148</td>\n",
       "      <td>8.15</td>\n",
       "      <td>0.1963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen3-0.6B-openmath_SFT_None_Lora32</th>\n",
       "      <td>23919.390779</td>\n",
       "      <td>1.5776</td>\n",
       "      <td>0.8702</td>\n",
       "      <td>0.5095</td>\n",
       "      <td>0.1564</td>\n",
       "      <td>0.3305</td>\n",
       "      <td>8.48</td>\n",
       "      <td>0.1963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen3-0.6B-squad_SFT_None_Lora32</th>\n",
       "      <td>23523.160626</td>\n",
       "      <td>1.9676</td>\n",
       "      <td>0.3095</td>\n",
       "      <td>0.5024</td>\n",
       "      <td>0.1519</td>\n",
       "      <td>0.3148</td>\n",
       "      <td>9.59</td>\n",
       "      <td>0.1950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen3-0.6B_base</th>\n",
       "      <td>24834.379745</td>\n",
       "      <td>6.0139</td>\n",
       "      <td>1.1397</td>\n",
       "      <td>0.4932</td>\n",
       "      <td>0.1794</td>\n",
       "      <td>0.3940</td>\n",
       "      <td>10.07</td>\n",
       "      <td>0.2274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen3-1.7B_base</th>\n",
       "      <td>742.251114</td>\n",
       "      <td>12.5197</td>\n",
       "      <td>3.4025</td>\n",
       "      <td>0.7986</td>\n",
       "      <td>0.2171</td>\n",
       "      <td>0.0099</td>\n",
       "      <td>30.36</td>\n",
       "      <td>0.2837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     OpenMathInstruct-2__avg_abs_diff  \\\n",
       "model                                                                   \n",
       "Qwen3-0.6B-arc_SFT_None_Lora32                           22870.653666   \n",
       "Qwen3-0.6B-arc_SFT_None_Lora64                           22870.688842   \n",
       "Qwen3-0.6B-boolq_SFT_None_Lora32                         25172.044530   \n",
       "Qwen3-0.6B-openmath_SFT_None_Lora32                      23919.390779   \n",
       "Qwen3-0.6B-squad_SFT_None_Lora32                         23523.160626   \n",
       "Qwen3-0.6B_base                                          24834.379745   \n",
       "Qwen3-1.7B_base                                            742.251114   \n",
       "\n",
       "                                     OpenMathInstruct-2__latency_mean_s  \\\n",
       "model                                                                     \n",
       "Qwen3-0.6B-arc_SFT_None_Lora32                                   0.4439   \n",
       "Qwen3-0.6B-arc_SFT_None_Lora64                                   0.1811   \n",
       "Qwen3-0.6B-boolq_SFT_None_Lora32                                 4.7384   \n",
       "Qwen3-0.6B-openmath_SFT_None_Lora32                              1.5776   \n",
       "Qwen3-0.6B-squad_SFT_None_Lora32                                 1.9676   \n",
       "Qwen3-0.6B_base                                                  6.0139   \n",
       "Qwen3-1.7B_base                                                 12.5197   \n",
       "\n",
       "                                     ai2_arc__latency_mean_s  \\\n",
       "model                                                          \n",
       "Qwen3-0.6B-arc_SFT_None_Lora32                        0.1595   \n",
       "Qwen3-0.6B-arc_SFT_None_Lora64                        0.1601   \n",
       "Qwen3-0.6B-boolq_SFT_None_Lora32                      0.9745   \n",
       "Qwen3-0.6B-openmath_SFT_None_Lora32                   0.8702   \n",
       "Qwen3-0.6B-squad_SFT_None_Lora32                      0.3095   \n",
       "Qwen3-0.6B_base                                       1.1397   \n",
       "Qwen3-1.7B_base                                       3.4025   \n",
       "\n",
       "                                     ai2_arc__macro_f1  boolq__latency_mean_s  \\\n",
       "model                                                                           \n",
       "Qwen3-0.6B-arc_SFT_None_Lora32                  0.4880                 0.1599   \n",
       "Qwen3-0.6B-arc_SFT_None_Lora64                  0.4937                 0.1587   \n",
       "Qwen3-0.6B-boolq_SFT_None_Lora32                0.5021                 0.1530   \n",
       "Qwen3-0.6B-openmath_SFT_None_Lora32             0.5095                 0.1564   \n",
       "Qwen3-0.6B-squad_SFT_None_Lora32                0.5024                 0.1519   \n",
       "Qwen3-0.6B_base                                 0.4932                 0.1794   \n",
       "Qwen3-1.7B_base                                 0.7986                 0.2171   \n",
       "\n",
       "                                     boolq__macro_f1  squad_v2__F1  \\\n",
       "model                                                                \n",
       "Qwen3-0.6B-arc_SFT_None_Lora32                0.3367          8.59   \n",
       "Qwen3-0.6B-arc_SFT_None_Lora64                0.3241          8.09   \n",
       "Qwen3-0.6B-boolq_SFT_None_Lora32              0.3148          8.15   \n",
       "Qwen3-0.6B-openmath_SFT_None_Lora32           0.3305          8.48   \n",
       "Qwen3-0.6B-squad_SFT_None_Lora32              0.3148          9.59   \n",
       "Qwen3-0.6B_base                               0.3940         10.07   \n",
       "Qwen3-1.7B_base                               0.0099         30.36   \n",
       "\n",
       "                                     squad_v2__latency_mean_s  \n",
       "model                                                          \n",
       "Qwen3-0.6B-arc_SFT_None_Lora32                         0.1958  \n",
       "Qwen3-0.6B-arc_SFT_None_Lora64                         0.1952  \n",
       "Qwen3-0.6B-boolq_SFT_None_Lora32                       0.1963  \n",
       "Qwen3-0.6B-openmath_SFT_None_Lora32                    0.1963  \n",
       "Qwen3-0.6B-squad_SFT_None_Lora32                       0.1950  \n",
       "Qwen3-0.6B_base                                        0.2274  \n",
       "Qwen3-1.7B_base                                        0.2837  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "# ---- Config ----\n",
    "metrics_dir = Path(\"metrics\")\n",
    "out_csv = Path(\"metrics_summary.csv\")\n",
    "\n",
    "def dataset_slug(name: str) -> str:\n",
    "    \"\"\"\n",
    "    Convert file name to a compact slug:\n",
    "    'test-ai2_arc.parquet' -> 'ai2_arc'\n",
    "    \"\"\"\n",
    "    n = Path(name).stem  # removes .parquet\n",
    "    if n.startswith(\"test-\"):\n",
    "        n = n[5:]\n",
    "    return n\n",
    "\n",
    "def get_metric(ds_block: dict, key: str):\n",
    "    \"\"\"\n",
    "    Try to retrieve a metric first at the dataset level, then inside 'metrics'.\n",
    "    \"\"\"\n",
    "    val = ds_block.get(key)\n",
    "    if val is None:\n",
    "        val = (ds_block.get(\"metrics\") or {}).get(key)\n",
    "    return val\n",
    "\n",
    "# Efficacy policy (in order of preference) by dataset type\n",
    "EFFICACY_POLICY = {\n",
    "    \"mcq4\": [\"macro_f1\", \"accuracy\"],\n",
    "    \"boolq\": [\"macro_f1\", \"MCC\", \"balanced_accuracy\", \"accuracy\"],\n",
    "    \"squad_v2\": [\"F1\", \"EM\"],\n",
    "    \"math_numeric\": [\"avg_abs_diff\"],  # lower is better; we keep the raw value\n",
    "}\n",
    "\n",
    "def choose_efficacy_metric(ds_block: dict) -> Optional[Tuple[str, float]]:\n",
    "    \"\"\"\n",
    "    Return the chosen (metric_name, value) according to EFFICACY_POLICY.\n",
    "    Falls back to common keys if the preferred ones are missing.\n",
    "    \"\"\"\n",
    "    kind = ds_block.get(\"type\", \"\")\n",
    "    candidates = EFFICACY_POLICY.get(kind, [])\n",
    "    for k in candidates:\n",
    "        v = get_metric(ds_block, k)\n",
    "        if v is not None:\n",
    "            return k, v\n",
    "\n",
    "    # Generic fallback for unknown/new dataset types\n",
    "    for k in [\"accuracy\", \"macro_f1\", \"F1\", \"balanced_accuracy\", \"MCC\", \"EM\", \"avg_abs_diff\"]:\n",
    "        v = get_metric(ds_block, k)\n",
    "        if v is not None:\n",
    "            return k, v\n",
    "\n",
    "    return None\n",
    "\n",
    "rows = []\n",
    "\n",
    "for jf in sorted(metrics_dir.glob(\"*.json\")):\n",
    "    with open(jf, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    model_id = jf.stem  # use file name without extension as model id\n",
    "    row = {\"model\": model_id}\n",
    "\n",
    "    datasets = data.get(\"datasets\", {}) or {}\n",
    "    for ds_name, ds_block in datasets.items():\n",
    "        slug = dataset_slug(ds_name)\n",
    "\n",
    "        # 1) Efficacy: exactly one metric per dataset\n",
    "        eff = choose_efficacy_metric(ds_block)\n",
    "        if eff is not None:\n",
    "            metric_name, value = eff\n",
    "            row[f\"{slug}__{metric_name}\"] = value\n",
    "\n",
    "        # 2) Efficiency: latency mean in seconds\n",
    "        lat_mean = (ds_block.get(\"latency_seconds\") or {}).get(\"mean\")\n",
    "        row[f\"{slug}__latency_mean_s\"] = lat_mean\n",
    "\n",
    "    rows.append(row)\n",
    "\n",
    "# Build DataFrame\n",
    "if rows:\n",
    "    df = pd.DataFrame(rows).set_index(\"model\").sort_index(axis=1)\n",
    "else:\n",
    "    df = pd.DataFrame(columns=[\"model\"]).set_index(\"model\")\n",
    "\n",
    "# Save CSV\n",
    "out_csv.parent.mkdir(parents=True, exist_ok=True)\n",
    "df.to_csv(out_csv, index=True)\n",
    "\n",
    "print(f\"âœ… Wrote summary with shape {df.shape} to: {out_csv}\")\n",
    "# with pd.option_context(\"display.max_columns\", None, \"display.width\", 200):\n",
    "#     print(df)\n",
    "    \n",
    "df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32f5a64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ghiki\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50cc5cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "datasets = {\n",
    "    \"squad_v2\": {\n",
    "                \"train\": \"hf://datasets/rajpurkar/squad_v2/squad_v2/train-00000-of-00001.parquet\",\n",
    "                \"test\": \"hf://datasets/rajpurkar/squad_v2/squad_v2/validation-00000-of-00001.parquet\"\n",
    "            },\n",
    "    \"ai2_arc\": {\n",
    "                \"train\": \"hf://datasets/allenai/ai2_arc/ARC-Challenge/train-00000-of-00001.parquet\",\n",
    "                \"test\": \"hf://datasets/allenai/ai2_arc/ARC-Challenge/test-00000-of-00001.parquet\"\n",
    "            },\n",
    "    \"boolq\": {\n",
    "                \"train\": \"hf://datasets/google/boolq/data/train-00000-of-00001.parquet\",\n",
    "                \"test\": \"hf://datasets/google/boolq/data/validation-00000-of-00001.parquet\"\n",
    "            }\n",
    "}\n",
    "\n",
    "def clean_data(dataset_name: str, df, type_of_dataset: str):\n",
    "    match dataset_name:\n",
    "        case \"squad_v2\":\n",
    "            df[\"answers\"] = df[\"answers\"].apply(\n",
    "                lambda x: x[\"text\"][0] if len(x.get(\"text\")) > 0 else \"\"\n",
    "            )\n",
    "            df.rename(\n",
    "                columns={\n",
    "                    \"answers\": \"answer\",\n",
    "                },\n",
    "                inplace=True,\n",
    "            )\n",
    "            df.drop(columns=\"id\", inplace=True)\n",
    "        case \"ai2_arc\":\n",
    "            df[\"choices\"] = df[\"choices\"].apply(\n",
    "                lambda x: \" \".join(\n",
    "                    [f\"{label}. {text}\" for label, text in zip(x[\"label\"], x[\"text\"])]\n",
    "                )\n",
    "            )\n",
    "            df[\"question\"] = df[\"question\"] + \" \" + df[\"choices\"]\n",
    "            df.rename(\n",
    "                columns={\n",
    "                    \"id\": \"title\",\n",
    "                    \"answerKey\": \"answer\",\n",
    "                },\n",
    "                inplace=True,\n",
    "            )\n",
    "            df.drop(columns=\"choices\", inplace=True)\n",
    "        case \"boolq\":\n",
    "            df.rename(\n",
    "                columns={\n",
    "                    \"passage\": \"context\",\n",
    "                },\n",
    "                inplace=True,\n",
    "            )\n",
    "\n",
    "    df.to_parquet(f\"../Datasets/{type_of_dataset}-{dataset_name}.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9aecebde",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_name in datasets.keys():\n",
    "    dataset = datasets[dataset_name]\n",
    "    for type_of_dataset in dataset.keys():\n",
    "        df = pd.read_parquet(dataset[type_of_dataset])\n",
    "        clean_data(dataset_name, df, type_of_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5e4a324",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"nvidia/OpenMathInstruct-2\", split=\"train\", streaming=True)\n",
    "\n",
    "# Solo tomar 10k ejemplos sin descargar todo\n",
    "subset = []\n",
    "for i, example in enumerate(dataset):\n",
    "    if i >= 10000:\n",
    "        break\n",
    "    subset.append(example)\n",
    "\n",
    "df = pd.DataFrame(subset)\n",
    "\n",
    "# Eliminar columnas innecesarias\n",
    "df = df.drop(columns=[\"generated_solution\", \"problem_source\"], errors=\"ignore\")\n",
    "\n",
    "# Renombrar columna\n",
    "df = df.rename(columns={\"expected_answer\": \"answer\"})\n",
    "\n",
    "# Filtrar filas donde 'answer' no es un n√∫mero\n",
    "df = df[df[\"answer\"].apply(lambda x: isinstance(x, (int, float)) or (isinstance(x, str) and x.replace('.', '', 1).isdigit()))]\n",
    "\n",
    "# Convertir 'answer' a float\n",
    "df[\"answer\"] = df[\"answer\"].astype(float)\n",
    "\n",
    "# Separar en train y test (80% train, 20% test)\n",
    "train_df = df.sample(frac=0.8, random_state=42)\n",
    "test_df = df.drop(train_df.index)\n",
    "\n",
    "# Guardar en disco\n",
    "train_df.to_parquet(\"../Datasets/train-OpenMathInstruct-2.parquet\")\n",
    "test_df.to_parquet(\"../Datasets/test-OpenMathInstruct-2.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
